# -*- coding: utf-8 -*-
"""SpacySimilarity

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S0sa0caYijVYyTm_sgFsjeDkaFBm32qn
"""

class SpacySimilarity(object):
  def __init__(self, nlp):
    self.nlp = nlp

  def __calcular_media(self, valores):
    d = len(valores)
    sum = 0;
    for v in valores:
      sum = sum + v;
    #print('MEDIA: ',sum/d)
    return sum/d
  '''
  def __countstr(string):
    splt = string.split(" ")
    #print("------------", len(splt))
    return len(splt)
  '''
  def __similaridade(self, string1, string2, prob1 = {}, prob2 = {}):
    doc1 = self.nlp(string1)
    doc2 = self.nlp(string2)
    valores = []
    size = len(string1.split(' '))
    aux = size 
    for token1 in doc1:
      size1 = len(string2.split(' '))
      aux1 = size1 

      for token2 in doc2:
        if token2.has_vector and token1.has_vector:
          v = token1.similarity(token2)

          if self.rank_matters == True and self.include_prob == False:
            valores.append((v*aux/size) * (v*aux1/size1))

          elif self.rank_matters == True and self.include_prob == True:

            if token1.text in prob1.keys() and token2.text in prob2.keys():
              valores.append( (v*aux/size) * (v*aux1/size1) + (prob1[token1.text] + prob2[token2.text]))
            else:
              valores.append( (v*aux/size) * (v*aux1/size1))

          elif self.rank_matters == False and self.include_prob == True:

            if token1.text in prob1.keys() and token2.text in prob2.keys():
              valores.append((v) + (prob1[token1.text] + prob2[token2.text])) 

            else:

              valores.append((v)) 

          elif self.rank_matters == False and self.include_prob == False:
            valores.append(v) 

        elif token2.text == token1.text:
    
          if self.rank_matters:

            valores.append(1 + aux/size * aux1/size1)

          else:
            valores.append(1)

        aux1 -= 1
      aux -= 1
    med = self.__calcular_media(valores)
    return med

  def __has_vec(self, string):
    doc = self.nlp(string)
    for token in doc:
      return token.has_vector

  def __remove(self, lista):
    topicos = []
    for t in lista:
      lista_aux = []
      for word in t:
        if "_"  in word:
          aux = word.split('_')
          if self.__has_vec(aux[0]+aux[1]):
            lista_aux.append((aux[0]+aux[1]))
          lista_aux.append(aux[0])
          lista_aux.append(aux[1])

        lista_aux.append(word)
      topicos.append(lista_aux)
      
    return topicos

  def spacy_simi(self, topicost1, topicost2, prob1 = {}, prob2 = {}, rank_matters = False, include_prob = False):

    self.rank_matters = rank_matters 
    self.include_prob = include_prob

    if include_prob:
      if len(prob1.keys()) != len(topicost1) and len(prob2.keys()) != len(topicost2):
        raise Exception('dictionary size does not match the list size')
        
    topicost1 = self.__remove(topicost1)
    topicost2 = self.__remove(topicost2)
    medias = []

    for topico1 in range(len(topicost1)):
        string1 = " ".join(w for w in topicost1[topico1])
        maior_media = 0
        v = []
        melhor_topico = 0
        for topico2 in range(len(topicost2)):
          string2 = " ".join(w for w in topicost2[topico2])
          #print("{} - {} ---COM --- {} - {}".format(topico2, string2, topico1, string1))
          if include_prob:
            m = self.__similaridade(string1, string2, prob1[topico1], prob2[topico2])
          else:
            m = self.__similaridade(string1, string2) 

          v.append([m])
          media = m
          if media > maior_media:
            maior_media = media
            melhor_topico = topico2

        medias.append([topico1, melhor_topico, maior_media])
    return medias

  def make_dict(self, topicos, probs):
    t1Dict = {}
    for idx, t in enumerate(topicos):
      t1Dict[idx] = {}
      for idx2, word in enumerate(t):
        t1Dict[idx][word] = probs[idx][idx2]
    return t1Dict